# ğŸ¤– ONNXäººè„¸æ£€æµ‹æ¨¡å‹ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†é¡¹ç›®ä¸­ä½¿ç”¨çš„ONNXäººè„¸æ£€æµ‹æ¨¡å‹çš„è¾“å…¥è¾“å‡ºæ ¼å¼ã€ä½¿ç”¨æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

## ğŸ“‹ ç›®å½•
- [æ¨¡å‹æ¦‚è¿°](#æ¨¡å‹æ¦‚è¿°)
- [è¾“å…¥æ ¼å¼è¯¦è§£](#è¾“å…¥æ ¼å¼è¯¦è§£)
- [è¾“å‡ºæ ¼å¼è¯¦è§£](#è¾“å‡ºæ ¼å¼è¯¦è§£)
- [é¢„å¤„ç†æ­¥éª¤](#é¢„å¤„ç†æ­¥éª¤)
- [åå¤„ç†æ­¥éª¤](#åå¤„ç†æ­¥éª¤)
- [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)
- [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## ğŸ¯ æ¨¡å‹æ¦‚è¿°

é¡¹ç›®æ”¯æŒå¤šä¸ªONNXäººè„¸æ£€æµ‹æ¨¡å‹ï¼ŒåŸºäºUltra-Light-Fast-Generic-Face-Detectoræ¶æ„ï¼š

| æ¨¡å‹åç§° | è¾“å…¥å°ºå¯¸ | æ–‡ä»¶å¤§å° | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|---------|
| `version-RFB-320.onnx` | 320Ã—240 | ~1.2MB | å¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦ |
| `version-RFB-640.onnx` | 640Ã—480 | ~1.2MB | é«˜ç²¾åº¦æ£€æµ‹ |
| `version-slim-320.onnx` | 320Ã—240 | ~0.3MB | è½»é‡çº§å¿«é€Ÿæ£€æµ‹ |
| `version-RFB-320_simplified.onnx` | 320Ã—240 | ~1.2MB | ä¼˜åŒ–ç‰ˆæœ¬ |

## ğŸ” è¾“å…¥æ ¼å¼è¯¦è§£

### åŸºæœ¬ä¿¡æ¯
```
è¾“å…¥å¼ é‡åç§°: "input"
æ•°æ®ç±»å‹: float32
å¼ é‡å½¢çŠ¶: [Batch, Channels, Height, Width] (NCHWæ ¼å¼)
```

### å…·ä½“è§„æ ¼
```python
# RFB-320 å’Œ Slim-320 æ¨¡å‹
input_shape = [1, 3, 240, 320]  # [N, C, H, W]

# RFB-640 æ¨¡å‹  
input_shape = [1, 3, 480, 640]  # [N, C, H, W]
```

### ç»´åº¦è¯´æ˜
- **Batch (N)**: æ‰¹æ¬¡å¤§å°ï¼Œé€šå¸¸ä¸º 1
- **Channels (C)**: é¢œè‰²é€šé“æ•°ï¼ŒRGBå›¾åƒä¸º 3
- **Height (H)**: å›¾åƒé«˜åº¦
  - 320ç³»åˆ—æ¨¡å‹: 240åƒç´ 
  - 640ç³»åˆ—æ¨¡å‹: 480åƒç´   
- **Width (W)**: å›¾åƒå®½åº¦
  - 320ç³»åˆ—æ¨¡å‹: 320åƒç´ 
  - 640ç³»åˆ—æ¨¡å‹: 640åƒç´ 

### æ•°å€¼èŒƒå›´
- **åŸå§‹åƒç´ å€¼**: [0, 255] (uint8)
- **å½’ä¸€åŒ–å**: [-1, 1] (float32)

## ğŸ¯ è¾“å‡ºæ ¼å¼è¯¦è§£

æ¨¡å‹äº§ç”Ÿä¸¤ä¸ªè¾“å‡ºå¼ é‡ï¼š

### 1. ç½®ä¿¡åº¦åˆ†æ•° (scores)
```python
output_name: "scores"
shape: [1, 4420, 2]
dtype: float32
```

**ç»´åº¦è§£é‡Š:**
- `1`: æ‰¹æ¬¡å¤§å°
- `4420`: å€™é€‰æ£€æµ‹æ¡†çš„æ•°é‡
- `2`: ä¸¤ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°
  - ç´¢å¼• 0: èƒŒæ™¯ç½®ä¿¡åº¦
  - ç´¢å¼• 1: äººè„¸ç½®ä¿¡åº¦

**æ•°å€¼å«ä¹‰:**
```python
# å¯¹äºæ¯ä¸ªæ£€æµ‹æ¡† i
background_confidence = scores[0, i, 0]  # èƒŒæ™¯ç½®ä¿¡åº¦
face_confidence = scores[0, i, 1]        # äººè„¸ç½®ä¿¡åº¦

# é€šå¸¸ä½¿ç”¨ softmax æ¦‚ç‡ï¼Œå’Œä¸º 1
total_prob = background_confidence + face_confidence â‰ˆ 1.0
```

### 2. è¾¹ç•Œæ¡†åæ ‡ (boxes)
```python
output_name: "boxes"  
shape: [1, 4420, 4]
dtype: float32
```

**ç»´åº¦è§£é‡Š:**
- `1`: æ‰¹æ¬¡å¤§å°
- `4420`: ä¸ç½®ä¿¡åº¦å¯¹åº”çš„æ£€æµ‹æ¡†æ•°é‡
- `4`: è¾¹ç•Œæ¡†åæ ‡ `[x1, y1, x2, y2]`

**åæ ‡æ ¼å¼:**
```python
# å½’ä¸€åŒ–åæ ‡ (0-1 èŒƒå›´)
x1_norm, y1_norm, x2_norm, y2_norm = boxes[0, i, :]

# è½¬æ¢ä¸ºå®é™…åƒç´ åæ ‡
x1 = x1_norm * image_width
y1 = y1_norm * image_height  
x2 = x2_norm * image_width
y2 = y2_norm * image_height

# è®¡ç®—è¾¹ç•Œæ¡†å®½é«˜
width = x2 - x1
height = y2 - y1
```

## ğŸ”§ é¢„å¤„ç†æ­¥éª¤

### 1. å›¾åƒè¯»å–å’Œè½¬æ¢
```python
import cv2
import numpy as np

# è¯»å–å›¾åƒ (BGRæ ¼å¼)
image_bgr = cv2.imread('image.jpg')

# è½¬æ¢ä¸ºRGBæ ¼å¼
image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
```

### 2. å°ºå¯¸è°ƒæ•´
```python
# æ ¹æ®æ¨¡å‹è°ƒæ•´å›¾åƒå°ºå¯¸
if model_type == "320":
    target_width, target_height = 320, 240
elif model_type == "640":
    target_width, target_height = 640, 480

# è°ƒæ•´å›¾åƒå°ºå¯¸
resized_image = cv2.resize(image_rgb, (target_width, target_height))
```

### 3. å½’ä¸€åŒ–å¤„ç†
```python
# åƒç´ å€¼å½’ä¸€åŒ–åˆ° [-1, 1] èŒƒå›´
image_mean = np.array([127, 127, 127])  # RGBå‡å€¼
normalized_image = (resized_image - image_mean) / 128.0

# è½¬æ¢æ•°æ®ç±»å‹
normalized_image = normalized_image.astype(np.float32)
```

### 4. å¼ é‡é‡æ’
```python
# ä» HWC è½¬æ¢ä¸º CHW æ ¼å¼
chw_image = np.transpose(normalized_image, [2, 0, 1])

# æ·»åŠ æ‰¹æ¬¡ç»´åº¦: CHW -> NCHW
input_tensor = np.expand_dims(chw_image, axis=0)

# æœ€ç»ˆè¾“å…¥å½¢çŠ¶: [1, 3, H, W]
print(f"è¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")
```

## âš™ï¸ åå¤„ç†æ­¥éª¤

### 1. ONNXæ¨ç†
```python
import onnxruntime as ort

# åˆ›å»ºæ¨ç†ä¼šè¯
session = ort.InferenceSession('model.onnx')
input_name = session.get_inputs()[0].name

# è¿è¡Œæ¨ç†
outputs = session.run(None, {input_name: input_tensor})
confidences, boxes = outputs[0], outputs[1]
```

### 2. ç½®ä¿¡åº¦è¿‡æ»¤
```python
def filter_faces(confidences, boxes, threshold=0.7):
    """æ ¹æ®ç½®ä¿¡åº¦è¿‡æ»¤äººè„¸æ£€æµ‹ç»“æœ"""
    # æå–äººè„¸ç½®ä¿¡åº¦ (ç´¢å¼•1)
    face_scores = confidences[0, :, 1]
    
    # åº”ç”¨é˜ˆå€¼è¿‡æ»¤
    valid_indices = face_scores > threshold
    
    # ç­›é€‰æœ‰æ•ˆçš„æ¡†å’Œåˆ†æ•°
    filtered_boxes = boxes[0, valid_indices, :]
    filtered_scores = face_scores[valid_indices]
    
    return filtered_boxes, filtered_scores
```

### 3. åæ ‡è½¬æ¢
```python
def convert_coordinates(boxes, original_width, original_height):
    """å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºå®é™…åƒç´ åæ ‡"""
    # å¤åˆ¶æ•°ç»„é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    pixel_boxes = boxes.copy()
    
    # è½¬æ¢ x åæ ‡
    pixel_boxes[:, [0, 2]] *= original_width   # x1, x2
    
    # è½¬æ¢ y åæ ‡  
    pixel_boxes[:, [1, 3]] *= original_height  # y1, y2
    
    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
    pixel_boxes[:, [0, 2]] = np.clip(pixel_boxes[:, [0, 2]], 0, original_width)
    pixel_boxes[:, [1, 3]] = np.clip(pixel_boxes[:, [1, 3]], 0, original_height)
    
    return pixel_boxes.astype(np.int32)
```

### 4. éæå¤§å€¼æŠ‘åˆ¶ (NMS)
```python
def apply_nms(boxes, scores, iou_threshold=0.3):
    """åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶å»é™¤é‡å æ£€æµ‹æ¡†"""
    # è®¡ç®—é¢ç§¯
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    order = scores.argsort()[::-1]
    
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        
        # è®¡ç®—IoU
        xx1 = np.maximum(boxes[i, 0], boxes[order[1:], 0])
        yy1 = np.maximum(boxes[i, 1], boxes[order[1:], 1])
        xx2 = np.minimum(boxes[i, 2], boxes[order[1:], 2])
        yy2 = np.minimum(boxes[i, 3], boxes[order[1:], 3])
        
        w = np.maximum(0, xx2 - xx1)
        h = np.maximum(0, yy2 - yy1)
        
        intersection = w * h
        union = areas[i] + areas[order[1:]] - intersection
        iou = intersection / union
        
        # ä¿ç•™IoUå°äºé˜ˆå€¼çš„æ¡†
        order = order[1:][iou <= iou_threshold]
    
    return keep
```

## ğŸ’» å®Œæ•´ä»£ç ç¤ºä¾‹

```python
import cv2
import numpy as np
import onnxruntime as ort

def detect_faces(image_path, model_path, confidence_threshold=0.7):
    """å®Œæ•´çš„äººè„¸æ£€æµ‹æµç¨‹"""
    
    # 1. åŠ è½½æ¨¡å‹
    session = ort.InferenceSession(model_path)
    input_name = session.get_inputs()[0].name
    input_shape = session.get_inputs()[0].shape
    
    # è·å–æ¨¡å‹è¾“å…¥å°ºå¯¸
    model_height, model_width = input_shape[2], input_shape[3]
    
    # 2. è¯»å–å’Œé¢„å¤„ç†å›¾åƒ
    image_bgr = cv2.imread(image_path)
    original_height, original_width = image_bgr.shape[:2]
    
    # è½¬æ¢é¢œè‰²ç©ºé—´
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    
    # è°ƒæ•´å°ºå¯¸
    resized_image = cv2.resize(image_rgb, (model_width, model_height))
    
    # å½’ä¸€åŒ–
    image_mean = np.array([127, 127, 127])
    normalized_image = (resized_image - image_mean) / 128.0
    
    # é‡æ’ç»´åº¦å’Œæ·»åŠ æ‰¹æ¬¡
    input_tensor = np.transpose(normalized_image, [2, 0, 1])
    input_tensor = np.expand_dims(input_tensor, axis=0).astype(np.float32)
    
    # 3. æ¨ç†
    outputs = session.run(None, {input_name: input_tensor})
    confidences, boxes = outputs[0], outputs[1]
    
    # 4. åå¤„ç†
    # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
    face_scores = confidences[0, :, 1]
    valid_indices = face_scores > confidence_threshold
    
    filtered_boxes = boxes[0, valid_indices, :]
    filtered_scores = face_scores[valid_indices]
    
    if len(filtered_boxes) == 0:
        return []
    
    # è½¬æ¢åæ ‡
    pixel_boxes = filtered_boxes.copy()
    pixel_boxes[:, [0, 2]] *= original_width
    pixel_boxes[:, [1, 3]] *= original_height
    pixel_boxes = pixel_boxes.astype(np.int32)
    
    # åº”ç”¨NMS
    keep_indices = apply_nms(pixel_boxes, filtered_scores)
    
    # ç»„ç»‡ç»“æœ
    results = []
    for i in keep_indices:
        x1, y1, x2, y2 = pixel_boxes[i]
        confidence = filtered_scores[i]
        results.append({
            'bbox': (x1, y1, x2 - x1, y2 - y1),  # (x, y, w, h)
            'confidence': float(confidence),
            'coordinates': (x1, y1, x2, y2)       # (x1, y1, x2, y2)
        })
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    results = detect_faces(
        image_path="test_image.jpg",
        model_path="models/version-RFB-320.onnx",
        confidence_threshold=0.7
    )
    
    print(f"æ£€æµ‹åˆ° {len(results)} ä¸ªäººè„¸:")
    for i, result in enumerate(results):
        print(f"äººè„¸ {i+1}: è¾¹ç•Œæ¡†={result['bbox']}, ç½®ä¿¡åº¦={result['confidence']:.3f}")
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | è¾“å…¥å°ºå¯¸ | æ¨ç†æ—¶é—´* | å†…å­˜å ç”¨ | æ£€æµ‹ç²¾åº¦ | æ¨èç”¨é€” |
|------|---------|-----------|----------|----------|----------|
| RFB-320 | 320Ã—240 | ~15ms | ~50MB | â­â­â­â­ | é€šç”¨åœºæ™¯ |
| RFB-640 | 640Ã—480 | ~45ms | ~120MB | â­â­â­â­â­ | é«˜ç²¾åº¦è¦æ±‚ |
| Slim-320 | 320Ã—240 | ~8ms | ~30MB | â­â­â­ | å®æ—¶åº”ç”¨ |
| RFB-320_simplified | 320Ã—240 | ~12ms | ~45MB | â­â­â­â­ | ä¼˜åŒ–åœºæ™¯ |

*æ¨ç†æ—¶é—´åŸºäºCPUæµ‹è¯•ï¼Œå®é™…æ€§èƒ½å› ç¡¬ä»¶è€Œå¼‚

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæ£€æµ‹ä¸åˆ°äººè„¸ï¼Ÿ
**å¯èƒ½åŸå› :**
- ç½®ä¿¡åº¦é˜ˆå€¼è¿‡é«˜ï¼Œå°è¯•é™ä½åˆ° 0.5-0.6
- è¾“å…¥å›¾åƒå°ºå¯¸è¿‡å°ï¼Œäººè„¸åƒç´ å¤ªå°‘
- å›¾åƒè´¨é‡å·®ï¼Œæ¨¡ç³Šæˆ–å…‰ç…§ä¸ä½³

**è§£å†³æ–¹æ¡ˆ:**
```python
# é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
results = detect_faces(image_path, model_path, confidence_threshold=0.5)

# æ£€æŸ¥è¾“å…¥å›¾åƒå°ºå¯¸
print(f"å›¾åƒå°ºå¯¸: {image.shape}")
```

### Q2: æ£€æµ‹ç»“æœæœ‰é‡å¤æ¡†ï¼Ÿ
**åŸå› :** NMSé˜ˆå€¼è¿‡é«˜æˆ–æœªåº”ç”¨NMS

**è§£å†³æ–¹æ¡ˆ:**
```python
# é™ä½NMS IoUé˜ˆå€¼
keep_indices = apply_nms(boxes, scores, iou_threshold=0.3)
```

### Q3: åæ ‡è½¬æ¢é”™è¯¯ï¼Ÿ
**åŸå› :** å½’ä¸€åŒ–åæ ‡æœªæ­£ç¡®è½¬æ¢

**æ£€æŸ¥ä»£ç :**
```python
# ç¡®ä¿ä½¿ç”¨åŸå§‹å›¾åƒå°ºå¯¸ï¼Œä¸æ˜¯æ¨¡å‹è¾“å…¥å°ºå¯¸
pixel_boxes[:, [0, 2]] *= original_width   # ä¸æ˜¯ model_width
pixel_boxes[:, [1, 3]] *= original_height  # ä¸æ˜¯ model_height
```

### Q4: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Ÿ
**é€‰æ‹©æŒ‡å—:**
- **å®æ—¶åº”ç”¨**: Slim-320 (é€Ÿåº¦ä¼˜å…ˆ)
- **ä¸€èˆ¬ç”¨é€”**: RFB-320 (å¹³è¡¡æ€§èƒ½)
- **é«˜ç²¾åº¦**: RFB-640 (ç²¾åº¦ä¼˜å…ˆ)
- **ä¼˜åŒ–éƒ¨ç½²**: RFB-320_simplified (ä¼˜åŒ–ç‰ˆæœ¬)

### Q5: æ‰¹å¤„ç†å¦‚ä½•å®ç°ï¼Ÿ
**æ‰¹å¤„ç†ç¤ºä¾‹:**
```python
# ä¿®æ”¹è¾“å…¥ç»´åº¦æ”¯æŒæ‰¹å¤„ç†
batch_size = 4
input_tensor = np.zeros((batch_size, 3, 240, 320), dtype=np.float32)

for i, image in enumerate(batch_images):
    # é¢„å¤„ç†æ¯å¼ å›¾åƒ
    processed = preprocess_image(image)
    input_tensor[i] = processed

# æ‰¹é‡æ¨ç†
outputs = session.run(None, {input_name: input_tensor})
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [Ultra-Light-Fast-Generic-Face-Detector](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB)
- [ONNX Runtime å®˜æ–¹æ–‡æ¡£](https://onnxruntime.ai/)
- [OpenCV å›¾åƒå¤„ç†æ–‡æ¡£](https://docs.opencv.org/)

---

**æœ€åæ›´æ–°:** 2025å¹´5æœˆ24æ—¥  
**ç‰ˆæœ¬:** 1.0.0  
**ç»´æŠ¤è€…:** CV-project-new å›¢é˜Ÿ
